{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOXihtrgy62SujWNQAfEM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hub-ARIYAN/glens_detection_tpu/blob/main/Glens27.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gravitational Lens Detection with MobileNetV3\n",
        "# ==============================================\n",
        "#\n",
        "# ## Overview\n",
        "# This notebook trains a MobileNetV3-based binary classifier to detect gravitational lens images.\n",
        "# - **Class A (1)**: Lensed galaxies  \n",
        "# - **Class B (0)**: Non-lensed galaxies\n",
        "#\n",
        "# ## Quick Start\n",
        "# 1. Upload your CSV file with columns: `filename`, `label` (A/B)\n",
        "# 2. Upload/mount your PNG images directory\n",
        "# 3. Adjust hyperparameters in the \"Configuration\" section below\n",
        "# 4. Run all cells\n",
        "#\n",
        "# ## Key Features\n",
        "# - Two-phase training: frozen backbone ‚Üí fine-tuning\n",
        "# - Class imbalance handling (weighting/oversampling)\n",
        "# - Comprehensive evaluation with visualizations\n",
        "# - Grad-CAM interpretability\n",
        "# - Ablation experiments\n",
        "# - Full reproducibility with seeding\n",
        "#\n",
        "# ## Hardware Requirements\n",
        "# - GPU recommended (T4, V100, A100)\n",
        "# - ~8GB GPU memory for batch_size=32"
      ],
      "metadata": {
        "id": "X0cyk0ZmOgfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# CONFIGURATION & SETUP\n"
      ],
      "metadata": {
        "id": "CGm7qc0jOlaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core hyperparameters - adjust these as needed\n",
        "DATA_DIR = \"/content/images\"  # Directory containing PNG files\n",
        "CSV_PATH = \"/content/labels.csv\"  # CSV with filename,label columns\n",
        "BATCH_SIZE = 32  # Reduce to 16 if OOM\n",
        "IMG_SIZE = (224, 224)  # MobileNetV3 input size\n",
        "SPLIT = (0.8, 0.1, 0.1)  # Train/Val/Test split\n",
        "ACTIVATION = 'swish'  # Options: 'relu', 'leaky_relu', 'swish'\n",
        "FREEZE_EPOCHS = 10  # Phase 1: train head only\n",
        "TOTAL_EPOCHS = 50  # Total training epochs\n",
        "PATIENCE = 10  # Early stopping patience\n",
        "SEED = 42  # Reproducibility\n",
        "\n",
        "# Advanced options\n",
        "MOBILENET_VERSION = 'Large'  # 'Large' or 'Small'\n",
        "DROPOUT_RATE = 0.5\n",
        "HIDDEN_UNITS = 128\n",
        "USE_BATCH_NORM = True\n",
        "OVERSAMPLING_THRESHOLD = 10  # Use oversampling if imbalance > 1:10\n",
        "\n",
        "print(\"üöÄ Gravitational Lens Classifier Setup Complete!\")\n",
        "print(f\"Configuration: {MOBILENET_VERSION} MobileNetV3, {ACTIVATION} activation\")\n",
        "print(f\"Training strategy: {FREEZE_EPOCHS} frozen + {TOTAL_EPOCHS-FREEZE_EPOCHS} fine-tune epochs\")\n"
      ],
      "metadata": {
        "id": "SyzHnX6WOyHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# IMPORTS & ENVIRONMENT SETUP\n",
        "\n"
      ],
      "metadata": {
        "id": "lJD-a_I8PBb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import MobileNetV3Large, MobileNetV3Small\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"üîß Environment Setup:\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "    print(f\"GPU device: {tf.config.list_physical_devices('GPU')[0]}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Configure memory growth for GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU configuration error: {e}\")"
      ],
      "metadata": {
        "id": "l1ArSXh0PG0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# DATA LOADING & PREPROCESSING\n"
      ],
      "metadata": {
        "id": "_ndeFRtzPdCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path, data_dir, split_ratios=(0.8, 0.1, 0.1), seed=42):\n",
        "    \"\"\"\n",
        "    Load dataset from CSV and create train/val/test splits.\n",
        "\n",
        "    Args:\n",
        "        csv_path: Path to CSV with 'filename' and 'label' columns\n",
        "        data_dir: Directory containing PNG files\n",
        "        split_ratios: (train, val, test) split ratios\n",
        "        seed: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df, test_df, class_weights\n",
        "    \"\"\"\n",
        "    print(\"üìä Loading dataset...\")\n",
        "\n",
        "    # Read CSV and validate\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Loaded CSV with {len(df)} rows\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "    # Ensure required columns exist\n",
        "    if 'filename' not in df.columns or 'label' not in df.columns:\n",
        "        raise ValueError(\"CSV must contain 'filename' and 'label' columns\")\n",
        "\n",
        "    # Map labels A/B to 1/0\n",
        "    label_map = {'A': 1, 'B': 0}  # A = lensed, B = non-lensed\n",
        "    df['binary_label'] = df['label'].map(label_map)\n",
        "\n",
        "    # Check for missing mappings\n",
        "    if df['binary_label'].isna().any():\n",
        "        print(\"‚ö†Ô∏è Warning: Some labels couldn't be mapped. Unique labels:\", df['label'].unique())\n",
        "        df = df.dropna(subset=['binary_label'])\n",
        "\n",
        "    # Verify files exist\n",
        "    existing_files = []\n",
        "    missing_count = 0\n",
        "    for filename in df['filename']:\n",
        "        filepath = os.path.join(data_dir, filename)\n",
        "        if os.path.exists(filepath):\n",
        "            existing_files.append(True)\n",
        "        else:\n",
        "            existing_files.append(False)\n",
        "            missing_count += 1\n",
        "\n",
        "    df['file_exists'] = existing_files\n",
        "    df = df[df['file_exists']].copy()\n",
        "\n",
        "    if missing_count > 0:\n",
        "        print(f\"‚ö†Ô∏è Warning: {missing_count} files not found, using {len(df)} available files\")\n",
        "\n",
        "    # Class distribution analysis\n",
        "    class_counts = df['binary_label'].value_counts().sort_index()\n",
        "    print(f\"\\nüìà Class Distribution:\")\n",
        "    print(f\"Class 0 (Non-lensed): {class_counts.get(0, 0):,} samples\")\n",
        "    print(f\"Class 1 (Lensed): {class_counts.get(1, 0):,} samples\")\n",
        "\n",
        "    imbalance_ratio = class_counts.max() / class_counts.min() if class_counts.min() > 0 else float('inf')\n",
        "    print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "    # Calculate class weights\n",
        "    n_samples = len(df)\n",
        "    n_classes = 2\n",
        "    class_weights = {}\n",
        "    for class_id in [0, 1]:\n",
        "        class_weights[class_id] = n_samples / (n_classes * class_counts.get(class_id, 1))\n",
        "\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    # Create stratified splits\n",
        "    df_shuffled = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    # Stratified split to maintain class distribution\n",
        "    train_size = int(len(df_shuffled) * split_ratios[0])\n",
        "    val_size = int(len(df_shuffled) * split_ratios[1])\n",
        "\n",
        "    # Simple stratified approach\n",
        "    class_0_df = df_shuffled[df_shuffled['binary_label'] == 0]\n",
        "    class_1_df = df_shuffled[df_shuffled['binary_label'] == 1]\n",
        "\n",
        "    train_0 = class_0_df[:int(len(class_0_df) * split_ratios[0])]\n",
        "    val_0 = class_0_df[int(len(class_0_df) * split_ratios[0]):int(len(class_0_df) * (split_ratios[0] + split_ratios[1]))]\n",
        "    test_0 = class_0_df[int(len(class_0_df) * (split_ratios[0] + split_ratios[1])):]\n",
        "\n",
        "    train_1 = class_1_df[:int(len(class_1_df) * split_ratios[0])]\n",
        "    val_1 = class_1_df[int(len(class_1_df) * split_ratios[0]):int(len(class_1_df) * (split_ratios[0] + split_ratios[1]))]\n",
        "    test_1 = class_1_df[int(len(class_1_df) * (split_ratios[0] + split_ratios[1])):]\n",
        "\n",
        "    train_df = pd.concat([train_0, train_1]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    val_df = pd.concat([val_0, val_1]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "    test_df = pd.concat([test_0, test_1]).sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nüìä Split sizes:\")\n",
        "    print(f\"Train: {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"Val: {len(val_df):,} ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"Test: {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "\n",
        "    return train_df, val_df, test_df, class_weights, imbalance_ratio\n",
        "\n",
        "def create_data_pipeline(df, data_dir, batch_size, img_size, augment=False, cache=True):\n",
        "    \"\"\"\n",
        "    Create optimized tf.data pipeline for image loading and preprocessing.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'filename' and 'binary_label' columns\n",
        "        data_dir: Directory containing images\n",
        "        batch_size: Batch size for training\n",
        "        img_size: Target image size (height, width)\n",
        "        augment: Whether to apply data augmentation\n",
        "        cache: Whether to cache the dataset\n",
        "\n",
        "    Returns:\n",
        "        tf.data.Dataset\n",
        "    \"\"\"\n",
        "    # Create file paths and labels\n",
        "    filepaths = [os.path.join(data_dir, fname) for fname in df['filename']]\n",
        "    labels = df['binary_label'].values.astype(np.float32)\n",
        "\n",
        "    # Create dataset from file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
        "\n",
        "    # Image loading and preprocessing function\n",
        "    def load_and_preprocess_image(filepath, label):\n",
        "        # Load image\n",
        "        image = tf.io.read_file(filepath)\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "\n",
        "        # Resize and normalize\n",
        "        image = tf.image.resize(image, img_size)\n",
        "        image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    # Data augmentation function\n",
        "    def augment_image(image, label):\n",
        "        # Random horizontal flip\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        # Random vertical flip\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "\n",
        "        # Random rotation (small angles)\n",
        "        image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
        "\n",
        "        # Random brightness and contrast\n",
        "        image = tf.image.random_brightness(image, 0.1)\n",
        "        image = tf.image.random_contrast(image, 0.9, 1.1)\n",
        "\n",
        "        # Random zoom/shift simulation via random crop and resize\n",
        "        if tf.random.uniform([]) < 0.5:\n",
        "            crop_size = tf.random.uniform([], 0.85, 1.0)\n",
        "            h, w = img_size[0], img_size[1]\n",
        "            new_h = tf.cast(h * crop_size, tf.int32)\n",
        "            new_w = tf.cast(w * crop_size, tf.int32)\n",
        "            image = tf.image.random_crop(image, [new_h, new_w, 3])\n",
        "            image = tf.image.resize(image, img_size)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=0.02)\n",
        "        image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    # Apply loading and preprocessing\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Apply augmentation if requested\n",
        "    if augment:\n",
        "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Shuffle for training datasets\n",
        "    if augment:  # Assuming augment=True means training data\n",
        "        dataset = dataset.shuffle(buffer_size=min(1000, len(df)))\n",
        "\n",
        "    # Cache if requested and dataset is small enough\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    # Batch and prefetch\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "4CkYoxBQPiUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# MODEL ARCHITECTURE\n"
      ],
      "metadata": {
        "id": "2_fHdjZYPuUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activation_layer(activation_name):\n",
        "    \"\"\"Get activation layer by name.\"\"\"\n",
        "    if activation_name.lower() == 'relu':\n",
        "        return layers.ReLU()\n",
        "    elif activation_name.lower() == 'leaky_relu':\n",
        "        return layers.LeakyReLU(alpha=0.1)\n",
        "    elif activation_name.lower() in ['swish', 'hard_swish']:\n",
        "        return layers.Activation('swish')\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported activation: {activation_name}\")\n",
        "\n",
        "def create_mobilenet_classifier(img_size, mobilenet_version='Large', activation='swish',\n",
        "                               dropout_rate=0.5, hidden_units=128, use_batch_norm=True):\n",
        "    \"\"\"\n",
        "    Create MobileNetV3-based binary classifier.\n",
        "\n",
        "    Args:\n",
        "        img_size: Input image size (height, width, channels)\n",
        "        mobilenet_version: 'Large' or 'Small'\n",
        "        activation: Activation function name\n",
        "        dropout_rate: Dropout rate in classifier head\n",
        "        hidden_units: Hidden layer size\n",
        "        use_batch_norm: Whether to use batch normalization\n",
        "\n",
        "    Returns:\n",
        "        Compiled Keras model\n",
        "    \"\"\"\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=(*img_size, 3))\n",
        "\n",
        "    # MobileNetV3 backbone\n",
        "    if mobilenet_version.lower() == 'large':\n",
        "        backbone = MobileNetV3Large(\n",
        "            input_shape=(*img_size, 3),\n",
        "            include_top=False,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "    else:\n",
        "        backbone = MobileNetV3Small(\n",
        "            input_shape=(*img_size, 3),\n",
        "            include_top=False,\n",
        "            weights='imagenet'\n",
        "        )\n",
        "\n",
        "    # Freeze backbone initially\n",
        "    backbone.trainable = False\n",
        "\n",
        "    # Feature extraction\n",
        "    x = backbone(inputs, training=False)\n",
        "\n",
        "    # Classifier head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Hidden layer\n",
        "    x = layers.Dense(hidden_units)(x)\n",
        "    if use_batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = get_activation_layer(activation)(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-3),\n",
        "        loss=BinaryCrossentropy(),\n",
        "        metrics=[\n",
        "            BinaryAccuracy(name='accuracy'),\n",
        "            Precision(name='precision'),\n",
        "            Recall(name='recall'),\n",
        "            AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"üèóÔ∏è Created {mobilenet_version} MobileNetV3 with {activation} activation\")\n",
        "    print(f\"Backbone parameters: {backbone.count_params():,}\")\n",
        "    print(f\"Total parameters: {model.count_params():,}\")\n",
        "\n",
        "    return model, backbone\n"
      ],
      "metadata": {
        "id": "TKCAiBKmPz1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# TRAINING UTILITIES\n"
      ],
      "metadata": {
        "id": "3VdLA_8SQARA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(patience=10, monitor='val_auc', mode='max'):\n",
        "    \"\"\"Create training callbacks.\"\"\"\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor=monitor,\n",
        "            patience=patience,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1,\n",
        "            mode=mode\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=monitor,\n",
        "            factor=0.5,\n",
        "            patience=patience//2,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1,\n",
        "            mode=mode\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model.h5',\n",
        "            monitor=monitor,\n",
        "            save_best_only=True,\n",
        "            mode=mode,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    return callbacks\n",
        "\n",
        "def handle_class_imbalance(train_df, imbalance_ratio, threshold=10):\n",
        "    \"\"\"\n",
        "    Handle class imbalance using class weights or oversampling.\n",
        "\n",
        "    Args:\n",
        "        train_df: Training dataframe\n",
        "        imbalance_ratio: Ratio of majority to minority class\n",
        "        threshold: Use oversampling if imbalance > threshold\n",
        "\n",
        "    Returns:\n",
        "        Modified dataframe and class weights\n",
        "    \"\"\"\n",
        "    class_counts = train_df['binary_label'].value_counts().sort_index()\n",
        "\n",
        "    # Calculate class weights\n",
        "    n_samples = len(train_df)\n",
        "    class_weights = {\n",
        "        0: n_samples / (2 * class_counts.get(0, 1)),\n",
        "        1: n_samples / (2 * class_counts.get(1, 1))\n",
        "    }\n",
        "\n",
        "    if imbalance_ratio > threshold:\n",
        "        print(f\"‚öñÔ∏è High imbalance ({imbalance_ratio:.1f}:1), applying oversampling...\")\n",
        "\n",
        "        # Oversample minority class\n",
        "        minority_class = class_counts.idxmin()\n",
        "        majority_class = class_counts.idxmax()\n",
        "\n",
        "        minority_df = train_df[train_df['binary_label'] == minority_class]\n",
        "        majority_df = train_df[train_df['binary_label'] == majority_class]\n",
        "\n",
        "        # Calculate oversampling factor\n",
        "        target_size = len(majority_df)\n",
        "        oversample_factor = target_size // len(minority_df)\n",
        "        remainder = target_size % len(minority_df)\n",
        "\n",
        "        # Create oversampled dataset\n",
        "        oversampled_minority = pd.concat([minority_df] * oversample_factor +\n",
        "                                       [minority_df.sample(remainder, random_state=SEED)])\n",
        "\n",
        "        train_df = pd.concat([majority_df, oversampled_minority]).sample(\n",
        "            frac=1, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "        # Recalculate class weights\n",
        "        class_weights = {0: 1.0, 1: 1.0}  # Balanced after oversampling\n",
        "\n",
        "        print(f\"After oversampling: {len(train_df):,} samples\")\n",
        "    else:\n",
        "        print(f\"‚öñÔ∏è Using class weights (imbalance {imbalance_ratio:.1f}:1 < threshold {threshold})\")\n",
        "\n",
        "    return train_df, class_weights\n"
      ],
      "metadata": {
        "id": "wSYjHBfOQG93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION & VISUALIZATION"
      ],
      "metadata": {
        "id": "DfRGIDZbQfT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training curves.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss\n",
        "    axes[0,0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "    axes[0,0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    axes[0,0].set_title('Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0,0].set_xlabel('Epoch')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0,1].plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
        "    axes[0,1].plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
        "    axes[0,1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
        "    axes[0,1].set_xlabel('Epoch')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # AUC\n",
        "    axes[1,0].plot(history.history['auc'], label='Train AUC', linewidth=2)\n",
        "    axes[1,0].plot(history.history['val_auc'], label='Val AUC', linewidth=2)\n",
        "    axes[1,0].set_title('AUC', fontsize=14, fontweight='bold')\n",
        "    axes[1,0].set_xlabel('Epoch')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning Rate\n",
        "    if 'lr' in history.history:\n",
        "        axes[1,1].plot(history.history['lr'], linewidth=2, color='orange')\n",
        "        axes[1,1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
        "        axes[1,1].set_xlabel('Epoch')\n",
        "        axes[1,1].set_yscale('log')\n",
        "        axes[1,1].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[1,1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, test_dataset, test_df):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with metrics and visualizations.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        test_dataset: Test tf.data.Dataset\n",
        "        test_df: Test dataframe for additional analysis\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of metrics\n",
        "    \"\"\"\n",
        "    print(\"üìä Evaluating model...\")\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_proba = model.predict(test_dataset, verbose=0)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    y_true = test_df['binary_label'].values\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = (y_pred == y_true).mean()\n",
        "    precision = ((y_pred == 1) & (y_true == 1)).sum() / max((y_pred == 1).sum(), 1)\n",
        "    recall = ((y_pred == 1) & (y_true == 1)).sum() / max((y_true == 1).sum(), 1)\n",
        "    f1 = 2 * precision * recall / max(precision + recall, 1e-8)\n",
        "    auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
        "    auc_pr = average_precision_score(y_true, y_pred_proba)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'auc_roc': auc_roc,\n",
        "        'auc_pr': auc_pr\n",
        "    }\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"üéØ Test Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {auc_roc:.4f}\")\n",
        "    print(f\"PR-AUC: {auc_pr:.4f}\")\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])\n",
        "    axes[0,0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "    axes[0,0].set_xlabel('Predicted')\n",
        "    axes[0,0].set_ylabel('Actual')\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "    axes[0,1].plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {auc_roc:.3f})')\n",
        "    axes[0,1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "    axes[0,1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "    axes[0,1].set_xlabel('False Positive Rate')\n",
        "    axes[0,1].set_ylabel('True Positive Rate')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "    axes[1,0].plot(recall_curve, precision_curve, linewidth=2, label=f'PR (AUC = {auc_pr:.3f})')\n",
        "    axes[1,0].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
        "    axes[1,0].set_xlabel('Recall')\n",
        "    axes[1,0].set_ylabel('Precision')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Prediction Distribution\n",
        "    axes[1,1].hist(y_pred_proba[y_true == 0], bins=30, alpha=0.7, label='Non-lensed', color='red')\n",
        "    axes[1,1].hist(y_pred_proba[y_true == 1], bins=30, alpha=0.7, label='Lensed', color='blue')\n",
        "    axes[1,1].axvline(x=0.5, color='black', linestyle='--', alpha=0.8)\n",
        "    axes[1,1].set_title('Prediction Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[1,1].set_xlabel('Predicted Probability')\n",
        "    axes[1,1].set_ylabel('Count')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def create_gradcam_visualization(model, dataset, num_samples=4):\n",
        "    \"\"\"\n",
        "    Create Grad-CAM visualizations for model interpretability.\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        dataset: Dataset to sample from\n",
        "        num_samples: Number of samples to visualize\n",
        "    \"\"\"\n",
        "    print(\"üîç Generating Grad-CAM visualizations...\")\n",
        "\n",
        "    # Get a batch of images\n",
        "    for images, labels in dataset.take(1):\n",
        "        break\n",
        "\n",
        "    # Select samples\n",
        "    indices = np.random.choice(len(images), min(num_samples, len(images)), replace=False)\n",
        "    sample_images = tf.gather(images, indices)\n",
        "    sample_labels = tf.gather(labels, indices)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = model.predict(sample_images, verbose=0)\n",
        "\n",
        "    # Create Grad-CAM heatmaps\n",
        "    def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "        # First, we create a model that maps the input image to the activations\n",
        "        # of the last conv layer as well as the output predictions\n",
        "        grad_model = tf.keras.models.Model(\n",
        "            [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "        )\n",
        "\n",
        "        # Then, we compute the gradient of the top predicted class for our input image\n",
        "        # with respect to the activations of the last conv layer\n",
        "        with tf.GradientTape() as tape:\n",
        "            last_conv_layer_output, preds = grad_model(img_array)\n",
        "            if pred_index is None:\n",
        "                pred_index = tf.argmax(preds[0])\n",
        "            class_channel = preds[:, pred_index]\n",
        "\n",
        "        # This is the gradient of the output neuron (top predicted or chosen)\n",
        "        # with regard to the output feature map of the last conv layer\n",
        "        grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "        # This is a vector where each entry is the mean intensity of the gradient\n",
        "        # over a specific feature map channel\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "        # We multiply each channel in the feature map array\n",
        "        # by \"how important this channel is\" with regard to the top predicted class\n",
        "        # then sum all the channels to obtain the heatmap class activation\n",
        "        last_conv_layer_output = last_conv_layer_output[0]\n",
        "        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "        heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "        # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "        return heatmap.numpy()\n",
        "\n",
        "    # Find last convolutional layer\n",
        "    conv_layers = [layer.name for layer in model.layers if 'conv' in layer.name.lower()]\n",
        "    if not conv_layers:\n",
        "        # For MobileNetV3, find the last layer in the backbone\n",
        "        backbone_layers = [layer.name for layer in model.layers[1].layers if 'conv' in layer.name.lower()]\n",
        "        if backbone_layers:\n",
        "            last_conv_layer = f\"{model.layers[1].name}/{backbone_layers[-1]}\"\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Could not find convolutional layers for Grad-CAM\")\n",
        "            return\n",
        "    else:\n",
        "        last_conv_layer = conv_layers[-1]\n",
        "\n",
        "    # Create visualizations\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(-1, 1)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        img = sample_images[i]\n",
        "        true_label = int(sample_labels[i])\n",
        "        pred_prob = predictions[i][0]\n",
        "        pred_label = int(pred_prob > 0.5)\n",
        "\n",
        "        # Original image\n",
        "        axes[0, i].imshow(img)\n",
        "        axes[0, i].set_title(f'True: {true_label}, Pred: {pred_label}\\nProb: {pred_prob:.3f}')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        try:\n",
        "            # Generate Grad-CAM heatmap\n",
        "            heatmap = make_gradcam_heatmap(\n",
        "                tf.expand_dims(img, 0), model, last_conv_layer\n",
        "            )\n",
        "\n",
        "            # Resize heatmap to match image\n",
        "            heatmap_resized = tf.image.resize(\n",
        "                tf.expand_dims(heatmap, -1),\n",
        "                img.shape[:2]\n",
        "            ).numpy()[:, :, 0]\n",
        "\n",
        "            # Overlay heatmap on image\n",
        "            overlay = img.numpy() * 0.6 + plt.cm.jet(heatmap_resized)[:, :, :3] * 0.4\n",
        "            axes[1, i].imshow(overlay)\n",
        "            axes[1, i].set_title('Grad-CAM Heatmap')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Grad-CAM failed for sample {i}: {e}\")\n",
        "            axes[1, i].text(0.5, 0.5, 'Grad-CAM\\nUnavailable',\n",
        "                          transform=axes[1, i].transAxes, ha='center', va='center')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hVKclrTOQjcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN TRAINING PIPELINE"
      ],
      "metadata": {
        "id": "rKvZKwQxQpSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gravitational_lens_classifier():\n",
        "    \"\"\"Main training pipeline.\"\"\"\n",
        "    print(\"üåå Starting Gravitational Lens Detection Training Pipeline\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Check if running on CPU and adjust settings\n",
        "    if len(tf.config.list_physical_devices('GPU')) == 0:\n",
        "        print(\"‚ö° Running on CPU - optimizing for CPU performance\")\n",
        "        global BATCH_SIZE, FREEZE_EPOCHS, TOTAL_EPOCHS\n",
        "        # Reduce batch size and epochs for faster CPU training\n",
        "        BATCH_SIZE = min(BATCH_SIZE, 16)\n",
        "        FREEZE_EPOCHS = min(FREEZE_EPOCHS, 5)\n",
        "        TOTAL_EPOCHS = min(TOTAL_EPOCHS, 20)\n",
        "        print(f\"Adjusted: batch_size={BATCH_SIZE}, freeze_epochs={FREEZE_EPOCHS}, total_epochs={TOTAL_EPOCHS}\")\n",
        "\n",
        "    # Step 1: Load and prepare data\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 1: DATA LOADING & PREPARATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    train_df, val_df, test_df, initial_class_weights, imbalance_ratio = load_dataset(\n",
        "        CSV_PATH, DATA_DIR, SPLIT, SEED\n",
        "    )\n",
        "\n",
        "    # Handle class imbalance\n",
        "    train_df, class_weights = handle_class_imbalance(\n",
        "        train_df, imbalance_ratio, OVERSAMPLING_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # Step 2: Create data pipelines\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 2: DATA PIPELINE CREATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"üîÑ Creating data pipelines...\")\n",
        "    train_dataset = create_data_pipeline(\n",
        "        train_df, DATA_DIR, BATCH_SIZE, IMG_SIZE, augment=True, cache=False\n",
        "    )\n",
        "    val_dataset = create_data_pipeline(\n",
        "        val_df, DATA_DIR, BATCH_SIZE, IMG_SIZE, augment=False, cache=True\n",
        "    )\n",
        "    test_dataset = create_data_pipeline(\n",
        "        test_df, DATA_DIR, BATCH_SIZE, IMG_SIZE, augment=False, cache=True\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = len(train_df) // BATCH_SIZE\n",
        "    validation_steps = len(val_df) // BATCH_SIZE\n",
        "\n",
        "    print(f\"Training steps per epoch: {steps_per_epoch}\")\n",
        "    print(f\"Validation steps: {validation_steps}\")\n",
        "\n",
        "    # Step 3: Create model\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 3: MODEL CREATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    model, backbone = create_mobilenet_classifier(\n",
        "        IMG_SIZE, MOBILENET_VERSION, ACTIVATION, DROPOUT_RATE, HIDDEN_UNITS, USE_BATCH_NORM\n",
        "    )\n",
        "\n",
        "    print(f\"\\nüìã Model Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Step 4: Phase 1 Training (Frozen Backbone)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 4: PHASE 1 TRAINING (FROZEN BACKBONE)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    callbacks = create_callbacks(patience=PATIENCE//2, monitor='val_auc')\n",
        "\n",
        "    print(f\"üîí Training classifier head for {FREEZE_EPOCHS} epochs...\")\n",
        "    history_phase1 = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=FREEZE_EPOCHS,\n",
        "        validation_data=val_dataset,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Step 5: Phase 2 Training (Fine-tuning)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 5: PHASE 2 TRAINING (FINE-TUNING)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Unfreeze backbone\n",
        "    backbone.trainable = True\n",
        "\n",
        "    # Use lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),  # 10x lower\n",
        "        loss=BinaryCrossentropy(),\n",
        "        metrics=[\n",
        "            BinaryAccuracy(name='accuracy'),\n",
        "            Precision(name='precision'),\n",
        "            Recall(name='recall'),\n",
        "            AUC(name='auc')\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"üîì Fine-tuning full model for {TOTAL_EPOCHS - FREEZE_EPOCHS} more epochs...\")\n",
        "    print(f\"Unfrozen backbone with {backbone.count_params():,} trainable parameters\")\n",
        "\n",
        "    callbacks = create_callbacks(patience=PATIENCE, monitor='val_auc')\n",
        "\n",
        "    history_phase2 = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=TOTAL_EPOCHS - FREEZE_EPOCHS,\n",
        "        validation_data=val_dataset,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_steps=validation_steps,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Combine training histories\n",
        "    combined_history = keras.utils.get_custom_objects()\n",
        "    combined_history = type('', (), {})()\n",
        "    combined_history.history = {}\n",
        "\n",
        "    for key in history_phase1.history.keys():\n",
        "        combined_history.history[key] = (\n",
        "            history_phase1.history[key] + history_phase2.history[key]\n",
        "        )\n",
        "\n",
        "    # Step 6: Evaluation\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 6: MODEL EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Plot training curves\n",
        "    plot_training_history(combined_history)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    metrics = evaluate_model(model, test_dataset, test_df)\n",
        "\n",
        "    # Generate Grad-CAM visualizations\n",
        "    create_gradcam_visualization(model, test_dataset, num_samples=4)\n",
        "\n",
        "    return model, metrics, combined_history"
      ],
      "metadata": {
        "id": "UAg5GtEAQs31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABLATION EXPERIMENTS"
      ],
      "metadata": {
        "id": "WlqWGTdsQ01u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ablation_experiments():\n",
        "    \"\"\"\n",
        "    Run quick ablation experiments to compare different configurations.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ABLATION EXPERIMENTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load data once for all experiments\n",
        "    train_df, val_df, test_df, _, imbalance_ratio = load_dataset(\n",
        "        CSV_PATH, DATA_DIR, SPLIT, SEED\n",
        "    )\n",
        "    train_df, class_weights = handle_class_imbalance(\n",
        "        train_df, imbalance_ratio, OVERSAMPLING_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = create_data_pipeline(\n",
        "        train_df, DATA_DIR, BATCH_SIZE, IMG_SIZE, augment=True, cache=False\n",
        "    )\n",
        "    val_dataset = create_data_pipeline(\n",
        "        val_df, DATA_DIR, BATCH_SIZE, IMG_SIZE, augment=False, cache=True\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = len(train_df) // BATCH_SIZE\n",
        "    validation_steps = len(val_df) // BATCH_SIZE\n",
        "\n",
        "    # Experiment configurations\n",
        "    experiments = [\n",
        "        {'activation': 'relu', 'name': 'ReLU'},\n",
        "        {'activation': 'leaky_relu', 'name': 'LeakyReLU'},\n",
        "        {'activation': 'swish', 'name': 'Swish'},\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Reduce epochs for ablation (faster experiments)\n",
        "    ablation_epochs = min(15, TOTAL_EPOCHS)\n",
        "    ablation_freeze = min(5, FREEZE_EPOCHS)\n",
        "\n",
        "    for i, exp in enumerate(experiments):\n",
        "        print(f\"\\nüß™ Experiment {i+1}/{len(experiments)}: {exp['name']}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Create model with current configuration\n",
        "        model, backbone = create_mobilenet_classifier(\n",
        "            IMG_SIZE, MOBILENET_VERSION, exp['activation'],\n",
        "            DROPOUT_RATE, HIDDEN_UNITS, USE_BATCH_NORM\n",
        "        )\n",
        "\n",
        "        # Phase 1: Frozen training\n",
        "        callbacks = [EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True)]\n",
        "\n",
        "        history1 = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=ablation_freeze,\n",
        "            validation_data=val_dataset,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_steps=validation_steps,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=class_weights,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Phase 2: Fine-tuning\n",
        "        backbone.trainable = True\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=1e-4),\n",
        "            loss=BinaryCrossentropy(),\n",
        "            metrics=[BinaryAccuracy(name='accuracy'), AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        history2 = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=ablation_epochs - ablation_freeze,\n",
        "            validation_data=val_dataset,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_steps=validation_steps,\n",
        "            callbacks=callbacks,\n",
        "            class_weight=class_weights,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss, val_acc, val_auc = model.evaluate(val_dataset, verbose=0)\n",
        "        model_size = model.count_params()\n",
        "\n",
        "        results.append({\n",
        "            'Configuration': exp['name'],\n",
        "            'Val Accuracy': f\"{val_acc:.4f}\",\n",
        "            'Val AUC': f\"{val_auc:.4f}\",\n",
        "            'Model Size': f\"{model_size:,}\",\n",
        "            'Best Epoch': len(history1.history['loss']) + len(history2.history['loss'])\n",
        "        })\n",
        "\n",
        "        print(f\"‚úÖ {exp['name']}: Val AUC = {val_auc:.4f}, Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    # Display results table\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(f\"\\nüìä ABLATION RESULTS SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    return results_df\n"
      ],
      "metadata": {
        "id": "gipFStgIQ-NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILITY FUNCTIONS"
      ],
      "metadata": {
        "id": "_805X7MYQ_Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_data_samples(dataset, num_samples=8):\n",
        "    \"\"\"Visualize sample images from the dataset.\"\"\"\n",
        "    print(\"üñºÔ∏è Sample Images from Dataset:\")\n",
        "\n",
        "    # Get a batch\n",
        "    for images, labels in dataset.take(1):\n",
        "        break\n",
        "\n",
        "    # Select samples\n",
        "    indices = np.random.choice(len(images), min(num_samples, len(images)), replace=False)\n",
        "\n",
        "    # Plot\n",
        "    cols = 4\n",
        "    rows = (num_samples + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(15, 4*rows))\n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        row, col = i // cols, i % cols\n",
        "\n",
        "        img = images[idx]\n",
        "        label = int(labels[idx])\n",
        "        label_text = \"Lensed\" if label == 1 else \"Non-lensed\"\n",
        "\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].set_title(f'{label_text} (Class {label})', fontsize=12, fontweight='bold')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    # Hide extra subplots\n",
        "    for i in range(num_samples, rows * cols):\n",
        "        row, col = i // cols, i % cols\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_predictions(model, test_dataset, test_df, threshold=0.5):\n",
        "    \"\"\"Analyze model predictions in detail.\"\"\"\n",
        "    print(\"üîç Detailed Prediction Analysis\")\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_proba = model.predict(test_dataset, verbose=0).flatten()\n",
        "    y_pred = (y_pred_proba > threshold).astype(int)\n",
        "    y_true = test_df['binary_label'].values\n",
        "\n",
        "    # Create analysis dataframe\n",
        "    analysis_df = test_df.copy()\n",
        "    analysis_df['predicted_prob'] = y_pred_proba\n",
        "    analysis_df['predicted_label'] = y_pred\n",
        "    analysis_df['correct'] = (y_pred == y_true)\n",
        "\n",
        "    # Confidence analysis\n",
        "    high_conf_correct = ((y_pred_proba > 0.8) | (y_pred_proba < 0.2)) & analysis_df['correct']\n",
        "    low_conf_errors = ((y_pred_proba > 0.3) & (y_pred_proba < 0.7)) & ~analysis_df['correct']\n",
        "\n",
        "    print(f\"High confidence correct predictions: {high_conf_correct.sum()}/{len(analysis_df)} ({high_conf_correct.mean()*100:.1f}%)\")\n",
        "    print(f\"Low confidence errors: {low_conf_errors.sum()}/{len(analysis_df)} ({low_conf_errors.mean()*100:.1f}%)\")\n",
        "\n",
        "    # Show most confident correct and incorrect predictions\n",
        "    if high_conf_correct.any():\n",
        "        print(\"\\n‚úÖ Most confident correct predictions:\")\n",
        "        confident_correct = analysis_df[high_conf_correct].nlargest(3, 'predicted_prob')\n",
        "        for _, row in confident_correct.iterrows():\n",
        "            prob = row['predicted_prob']\n",
        "            print(f\"  {row['filename']}: True={row['binary_label']}, Pred={row['predicted_label']} (prob={prob:.3f})\")\n",
        "\n",
        "    if low_conf_errors.any():\n",
        "        print(\"\\n‚ùå Low confidence errors (review these):\")\n",
        "        low_conf_wrong = analysis_df[low_conf_errors].head(3)\n",
        "        for _, row in low_conf_wrong.iterrows():\n",
        "            prob = row['predicted_prob']\n",
        "            print(f\"  {row['filename']}: True={row['binary_label']}, Pred={row['predicted_label']} (prob={prob:.3f})\")\n",
        "\n",
        "    return analysis_df"
      ],
      "metadata": {
        "id": "ufZFkD6LRCPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENHANCED TRAINING WITH TENSORBOARD"
      ],
      "metadata": {
        "id": "ufeohHMYRHRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_tensorboard():\n",
        "    \"\"\"Setup TensorBoard logging.\"\"\"\n",
        "    import datetime\n",
        "    log_dir = f\"logs/fit/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        histogram_freq=1,\n",
        "        write_graph=True,\n",
        "        write_images=True,\n",
        "        update_freq='epoch'\n",
        "    )\n",
        "    return tensorboard_callback, log_dir\n",
        "\n",
        "def create_enhanced_callbacks(patience=10, monitor='val_auc', mode='max'):\n",
        "    \"\"\"Create enhanced training callbacks with TensorBoard.\"\"\"\n",
        "    tensorboard_callback, log_dir = setup_tensorboard()\n",
        "\n",
        "    callbacks = [\n",
        "        tensorboard_callback,\n",
        "        EarlyStopping(\n",
        "            monitor=monitor,\n",
        "            patience=patience,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1,\n",
        "            mode=mode\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor=monitor,\n",
        "            factor=0.5,\n",
        "            patience=patience//2,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1,\n",
        "            mode=mode\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_gravitational_lens_model.h5',\n",
        "            monitor=monitor,\n",
        "            save_best_only=True,\n",
        "            mode=mode,\n",
        "            verbose=1,\n",
        "            save_weights_only=False\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(f\"üìä TensorBoard logs will be saved to: {log_dir}\")\n",
        "    print(\"üí° To view TensorBoard: %tensorboard --logdir logs/fit\")\n",
        "\n",
        "    return callbacks.csv\", index=False)\n",
        "\n",
        "    # Save configuration\n",
        "    config = {\n",
        "        'DATA_DIR': DATA_DIR,\n",
        "        'BATCH_SIZE': BATCH_SIZE,\n",
        "        'IMG_SIZE': IMG_SIZE,\n",
        "        'SPLIT': SPLIT,\n",
        "        'ACTIVATION': ACTIVATION,\n",
        "        'FREEZE_EPOCHS': FREEZE_EPOCHS,\n",
        "        'TOTAL_EPOCHS': TOTAL_EPOCHS,\n",
        "        'MOBILENET_VERSION': MOBILENET_VERSION,\n",
        "        'DROPOUT_RATE': DROPOUT_RATE,\n",
        "        'HIDDEN_UNITS': HIDDEN_UNITS,\n",
        "        'SEED': SEED\n",
        "    }\n",
        "\n",
        "    config_df = pd.DataFrame([config])\n",
        "    config_df.to_csv(f\"{save_dir}/config.csv\", index=False)\n",
        "\n",
        "    print(f\"üìÅ All artifacts saved to {save_dir}/\")"
      ],
      "metadata": {
        "id": "MIXVlTLbRMcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINAL EXECUTION SECTION"
      ],
      "metadata": {
        "id": "hQ5t51uhRRqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function - run the complete training pipeline.\"\"\"\n",
        "    print(\"üé¨ Starting Gravitational Lens Classification Pipeline...\")\n",
        "    print(\"üî¨ Enhanced version with TensorBoard, detailed analysis, and ablations\")\n",
        "\n",
        "    try:\n",
        "        # Run main enhanced training pipeline\n",
        "        print(\"\\nüöÄ MAIN TRAINING PIPELINE\")\n",
        "        model, metrics, history, analysis = train_gravitational_lens_classifier_enhanced()\n",
        "\n",
        "        # Print final results summary\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üéä TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"üèÜ Final Test Results:\")\n",
        "        print(f\"   Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"   ROC-AUC:  {metrics['auc_roc']:.4f}\")\n",
        "        print(f\"   PR-AUC:   {metrics['auc_pr']:.4f}\")\n",
        "        print(f\"   F1-Score: {metrics['f1_score']:.4f}\")\n",
        "        print(f\"   Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"   Recall:   {metrics['recall']:.4f}\")\n",
        "\n",
        "        # Run ablation study (optional - comment out to skip)\n",
        "        print(\"\\nüî¨ RUNNING ABLATION STUDY...\")\n",
        "        print(\"This compares different activation functions and model sizes.\")\n",
        "        print(\"üí° Comment out the next line to skip ablation experiments and save time.\")\n",
        "\n",
        "        ablation_results = run_quick_ablation_study()\n",
        "\n",
        "        print(\"\\n‚ú® PIPELINE COMPLETE!\")\n",
        "        print(\"üìÅ Check the training_artifacts/ folder for saved models and logs\")\n",
        "        print(\"üìä Use %tensorboard --logdir logs/fit to view training in TensorBoard\")\n",
        "\n",
        "        return model, metrics, ablation_results\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"‚ùå File not found: {e}\")\n",
        "        print(\"üí° Please check that your DATA_DIR and CSV_PATH are correct\")\n",
        "        print(\"üí° Make sure your CSV has 'filename' and 'label' columns\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in training pipeline: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nüí° Common issues:\")\n",
        "        print(\"   - Check your data paths (DATA_DIR, CSV_PATH)\")\n",
        "        print(\"   - Verify CSV format (columns: filename, label)\")\n",
        "        print(\"   - Ensure sufficient GPU memory (reduce BATCH_SIZE if needed)\")\n",
        "        print(\"   - Check image file formats (should be PNG)\")\n"
      ],
      "metadata": {
        "id": "XjNm_PPJRVF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXECUTION BLOCK"
      ],
      "metadata": {
        "id": "RppYdtv5RX5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run the complete pipeline\n",
        "    main()"
      ],
      "metadata": {
        "id": "fnO3kMoORdcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COLAB-SPECIFIC INSTRUCTIONS AND UTILITIES"
      ],
      "metadata": {
        "id": "5P6FLfy4RhAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "üéØ GOOGLE COLAB QUICK SETUP GUIDE:\n",
        "==================================\n",
        "\n",
        "1Ô∏è‚É£ ENABLE GPU (STRONGLY RECOMMENDED):\n",
        "   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU ‚Üí Save\n",
        "\n",
        "2Ô∏è‚É£ UPLOAD YOUR DATA:\n",
        "\n",
        "   Option A - Direct Upload:\n",
        "   ```python\n",
        "   from google.colab import files\n",
        "   uploaded = files.upload()  # Upload your CSV and images\n",
        "   ```\n",
        "\n",
        "   Option B - Google Drive:\n",
        "   ```python\n",
        "   from google.colab import drive\n",
        "   drive.mount('/content/drive')\n",
        "   DATA_DIR = \"/content/drive/MyDrive/gravitational_lens_images/\"\n",
        "   CSV_PATH = \"/content/drive/MyDrive/gravitational_lens_labels.csv\"\n",
        "   ```\n",
        "\n",
        "3Ô∏è‚É£ ADJUST CONFIGURATION (edit the variables at the top):\n",
        "   - DATA_DIR: Path to your image directory\n",
        "   - CSV_PATH: Path to your labels CSV file\n",
        "   - BATCH_SIZE: Start with 32, reduce to 16 if out of memory\n",
        "   - TOTAL_EPOCHS: 50 is good for full training, 20 for quick tests\n",
        "\n",
        "4Ô∏è‚É£ RUN THE NOTEBOOK:\n",
        "   Runtime ‚Üí Run all (or run cell by cell)\n",
        "\n",
        "üìä CSV FORMAT REQUIRED:\n",
        "   Your CSV must have exactly these columns:\n",
        "   - filename: image filename (e.g., \"image_001.png\")\n",
        "   - label: \"A\" for lensed galaxies, \"B\" for non-lensed\n",
        "\n",
        "üìÇ DIRECTORY STRUCTURE:\n",
        "   Your images can be in subdirectories - the code will find them automatically!\n",
        "\n",
        "üîß EXPECTED PERFORMANCE (with good data):\n",
        "   - Training time: 2-4 hours on T4 GPU\n",
        "   - Memory usage: 6-10GB GPU RAM\n",
        "   - Target AUC: 0.90+ for quality datasets\n",
        "\n",
        "üí° TROUBLESHOOTING:\n",
        "   - OOM Error ‚Üí Reduce BATCH_SIZE to 16 or 8\n",
        "   - Slow training ‚Üí Make sure GPU is enabled\n",
        "   - File not found ‚Üí Check DATA_DIR and CSV_PATH\n",
        "   - Poor performance ‚Üí Check data quality and class balance\n",
        "\n",
        "üéâ WHAT YOU GET:\n",
        "   - Trained model (.h5 file)\n",
        "   - Training history plots\n",
        "   - Confusion matrix, ROC curves\n",
        "   - Grad-CAM visualizations\n",
        "   - Performance metrics\n",
        "   - TensorBoard logs\n",
        "   - Ablation study results\n",
        "\n",
        "Ready to detect gravitational lenses! üååüîç\n",
        "\"\"\")\n",
        "\n",
        "# Quick verification function\n",
        "def verify_setup():\n",
        "    \"\"\"Quick verification of setup and data paths.\"\"\"\n",
        "    print(\"üîç Verifying Setup...\")\n",
        "\n",
        "    print(f\"‚úì TensorFlow version: {tf.__version__}\")\n",
        "    print(f\"‚úì GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "\n",
        "    # Check if paths exist\n",
        "    if os.path.exists(DATA_DIR):\n",
        "        print(f\"‚úì Data directory found: {DATA_DIR}\")\n",
        "        png_files = []\n",
        "        for root, dirs, files in os.walk(DATA_DIR):\n",
        "            png_files.extend([f for f in files if f.lower().endswith('.png')])\n",
        "        print(f\"‚úì Found {len(png_files)} PNG files\")\n",
        "    else:\n",
        "        print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n",
        "\n",
        "    if os.path.exists(CSV_PATH):\n",
        "        print(f\"‚úì CSV file found: {CSV_PATH}\")\n",
        "        df = pd.read_csv(CSV_PATH)\n",
        "        print(f\"‚úì CSV has {len(df)} rows\")\n",
        "        print(f\"‚úì CSV columns: {list(df.columns)}\")\n",
        "\n",
        "        if 'filename' in df.columns and 'label' in df.columns:\n",
        "            print(\"‚úì Required columns found\")\n",
        "            label_counts = df['label'].value_counts()\n",
        "            print(f\"‚úì Label distribution: {dict(label_counts)}\")\n",
        "        else:\n",
        "            print(\"‚ùå Missing required columns: 'filename' and/or 'label'\")\n",
        "    else:\n",
        "        print(f\"‚ùå CSV file not found: {CSV_PATH}\")\n",
        "\n",
        "    print(\"\\nConfiguration:\")\n",
        "    print(f\"- Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"- Image size: {IMG_SIZE}\")\n",
        "    print(f\"- Activation: {ACTIVATION}\")\n",
        "    print(f\"- Training epochs: {TOTAL_EPOCHS} (freeze: {FREEZE_EPOCHS})\")\n",
        "\n",
        "# Uncomment to run verification\n",
        "# verify_setup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ6ZJIibRn7a",
        "outputId": "c4de7f2c-3afe-4c6e-cfd4-6670aae9d7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ GOOGLE COLAB QUICK SETUP GUIDE:\n",
            "==================================\n",
            "\n",
            "1Ô∏è‚É£ ENABLE GPU (STRONGLY RECOMMENDED):\n",
            "   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU ‚Üí Save\n",
            "\n",
            "2Ô∏è‚É£ UPLOAD YOUR DATA:\n",
            "   \n",
            "   Option A - Direct Upload:\n",
            "   ```python\n",
            "   from google.colab import files\n",
            "   uploaded = files.upload()  # Upload your CSV and images\n",
            "   ```\n",
            "   \n",
            "   Option B - Google Drive:\n",
            "   ```python\n",
            "   from google.colab import drive\n",
            "   drive.mount('/content/drive')\n",
            "   DATA_DIR = \"/content/drive/MyDrive/gravitational_lens_images/\"\n",
            "   CSV_PATH = \"/content/drive/MyDrive/gravitational_lens_labels.csv\"\n",
            "   ```\n",
            "\n",
            "3Ô∏è‚É£ ADJUST CONFIGURATION (edit the variables at the top):\n",
            "   - DATA_DIR: Path to your image directory\n",
            "   - CSV_PATH: Path to your labels CSV file\n",
            "   - BATCH_SIZE: Start with 32, reduce to 16 if out of memory\n",
            "   - TOTAL_EPOCHS: 50 is good for full training, 20 for quick tests\n",
            "\n",
            "4Ô∏è‚É£ RUN THE NOTEBOOK:\n",
            "   Runtime ‚Üí Run all (or run cell by cell)\n",
            "\n",
            "üìä CSV FORMAT REQUIRED:\n",
            "   Your CSV must have exactly these columns:\n",
            "   - filename: image filename (e.g., \"image_001.png\")  \n",
            "   - label: \"A\" for lensed galaxies, \"B\" for non-lensed\n",
            "\n",
            "üìÇ DIRECTORY STRUCTURE:\n",
            "   Your images can be in subdirectories - the code will find them automatically!\n",
            "   \n",
            "üîß EXPECTED PERFORMANCE (with good data):\n",
            "   - Training time: 2-4 hours on T4 GPU\n",
            "   - Memory usage: 6-10GB GPU RAM  \n",
            "   - Target AUC: 0.90+ for quality datasets\n",
            "   \n",
            "üí° TROUBLESHOOTING:\n",
            "   - OOM Error ‚Üí Reduce BATCH_SIZE to 16 or 8\n",
            "   - Slow training ‚Üí Make sure GPU is enabled\n",
            "   - File not found ‚Üí Check DATA_DIR and CSV_PATH\n",
            "   - Poor performance ‚Üí Check data quality and class balance\n",
            "\n",
            "üéâ WHAT YOU GET:\n",
            "   - Trained model (.h5 file)\n",
            "   - Training history plots  \n",
            "   - Confusion matrix, ROC curves\n",
            "   - Grad-CAM visualizations\n",
            "   - Performance metrics\n",
            "   - TensorBoard logs\n",
            "   - Ablation study results\n",
            "\n",
            "Ready to detect gravitational lenses! üååüîç\n",
            "\n"
          ]
        }
      ]
    }
  ]
}